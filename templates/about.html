<!doctype html>
<html>

    <head>
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
        <title>About - GI</title>
        <link rel="shortcut icon" href="{{ url_for('static', filename='favicon.ico') }}">
        <link rel="stylesheet" href="{{ url_for('static', filename='css/bootstrap.min.css') }}">
        <link rel="stylesheet" href="{{ url_for('static', filename='css/all.css') }}">
        <script src="{{ url_for('static', filename='js/modernizr.js') }}"></script>
        <style>
            body {
                width: 100vw;
                height: 100vh;
                background-color: rgb(0, 0, 0);
                font-family: 'Trebuchet MS', sans-serif;
                box-sizing: border-box;
                overflow-x: hidden;
                overflow-y: auto;
            }

            body:after {
                content: "";
                height: inherit;
                width: inherit;
                position: fixed;
                top: 0%;
                left: 0%;
                opacity: 0.9;
                background: linear-gradient(rgba(11, 12, 16, 0.8), rgba(11, 12, 16, 1));
                z-index: -1;
            }

            nav {
                position: fixed;
                top: 0;
                left: 0;
                height: auto;
                width: 100vw;
                background: #0b0c10;
            }

            header {
                font-family: "Oswald Stencil";
                position: fixed;
                text-align: center;
                font-size: 350%;
                top: 50%;
                width: 100%;
                left: 50%;
                transform: translate(-50%, -50%);
                z-index: -1;
                letter-spacing: 2px;
            }

            header .bold {
                font-weight: 700;
                text-transform: uppercase;
                color: transparent;
                /*text-shadow: -1px -1px 0 #000, 1px -1px 0 #000, -1px 1px 0 #000, 1px 1px 0 #000;*/
                text-shadow: -1px -1px 0px transparent, -1px -1px 0px transparent, -1px -1px 5px #00f7ff, -1px -1px 10px #00f7ff, -1px -1px 20px #055cb4;
                /*text-shadow: 0 0 5px transparent, 0 0 10px transparent, 0 0 15px #00f7ff, 0 0 20px #055cb4, 0 0 25px #055cb4, 0 0 30px #055cb4, 0 0 35px #055cb4;*/
                -webkit-text-stroke: 0.5px #00ffea;
                -webkit-text-fill-color: transparent;
                letter-spacing: 3px;
            }

            header .notBold {
                font-weight: 300;
                color: #056b6b;
                letter-spacing: 3px;
            }

            main {
                padding-top: 5em;
                color: white;
            }

            .heading {
                padding: 8px;
                text-align: center;
                color: #00f7ff;
            }

            .container .row {
                margin: 10px;
                background-color: rgba(11, 12, 16, 0.7);
            }

            .container h5 {
                text-align: left;
                padding: 0.5em 0.5em 0.5em 0.8em;
                background-color: rgba(2, 68, 77, 0.15);
                border-left: 5px solid #03c0b7;
                border-right: 5px solid #03c0b7;
            }

            .container p {
                font-family: 'Open Sans', 'Corbel';
                text-align: justify;
                font-size: 0.85em;
                letter-spacing: 0.5px;
                line-height: 1.8em;
            }

            #theory .theory_sub {
                font-family: 'Arial Narrow', Arial, sans-serif;
                margin: 2px;
                padding: 0.3em 0.5em;
                letter-spacing: 1px;
                font-size: 1.1em;
                font-weight: normal;
                border-right: 3px solid #039e9e;
                background-color: rgba(33, 86, 107, 0.35);
            }

            #references {
                text-align: justify;
            }

            #references li {
                padding: 5px;
                font-size: 0.9em;
            }

            #application_part {
                padding: 0px;
            }

            #application_part h2 {
                border-top: 2px solid #01b9b9;
                border-bottom: 2px solid #01b9b9;
                text-align: center;
                background-color: rgba(11, 12, 16, 0.3);
                padding: 10px;
                color: #00f7ff;
            }

            #application_part .content .sub_heading {
                font-weight: bold;
                padding-left: 30px;
            }

            #application_part .list_sub {
                letter-spacing: 0.5px;
                padding-left: 10px;
            }

            .list li {
                display: inline-flex;
                padding: 5px 10px;
                background-color: #056b6bd8;
            }

            #instruction_part {
                font-family: 'Lato';
            }

            #instruction_part li,
            #instruction_part .content p {
                font-size: 1em;
            }

            #instruction_part p {
                padding-left: 2em;
                margin: 0px;
            }

            pre {
                color: #056b6b;
                padding-left: 2em;
                margin: 0px;
            }

        </style>
        <script>
            document.onreadystatechange = function () {
                if (document.readyState !== "complete") {
                    document.querySelector("body").style.visibility = "hidden";
                    document.querySelector("#loader").style.visibility = "visible";
                } else {
                    document.querySelector("#loader").style.display = "none";
                    document.querySelector("body").style.visibility = "visible";
                }
            };
        </script>
    </head>

    <body>
        <div id="loader"></div>
        <nav class="navbar nav fixed-top d-flex justify-content-center">
            <ul>
                <li class="nav-item"><a href="index.html">Home</a></li>
            </ul>
        </nav>
        <header><span class="bold">Gender Idenification</span><span class="notBold"> by Voice </span></header>
        <main id="main">
            <h2 class="heading">Gender Identification by Voice</h2>
            <div class="container" id="theory">
                <div class="row">
                    <div class="col-lg-12">
                        <h5>Introduction</h5>
                        <div class="content">
                            <p style="text-indent: 50px;">Automatically detecting the gender of a speaker has several
                                potential applications. In the context of
                                Automatic Speech Recognition, gender dependent models are more accurate than gender
                                independent ones.
                                Hence, gender recognition is needed prior to the application of one gender dependent
                                model, (Acero and
                                Huang, 1996; Neti and Roukos, 1997). In the context of speaker recognition, perfect
                                gender detection can
                                improve the performance by limiting the search space to speakers from the same gender.
                                In content based
                                multimedia indexing, the speaker’s gender is a cue used in the annotation. Also, Gender
                                dependent speech
                                coders are more accurate than gender independent ones (Marston, 1998; Potamitis et al.,
                                2002). Therefore,
                                automatic gender detection can be an important tool in multimedia signal analysis
                                systems.
                                Several acoustic conditions exist in audio-visual data: compressed speech, telephone
                                quality speech, noisy
                                speech, speech over background music, studio quality speech, different languages, and so
                                on. Clearly, in this
                                context, a gender identification system must be able to process this variety of speech
                                conditions with acceptable
                                performance.<br><br>
                                <b class="theory_sub">Domain</b> Machine Learning.
                            </p>
                        </div>
                    </div>
                </div>
                <div class="row pt-3">
                    <div class="col-lg-12">
                        <h5>Terms and Definitions</h5>
                        <div class="content">
                            <p><b class="theory_sub">Machine Learning</b> It is an application of artificial
                                intelligence (AI) that provides systems the ability
                                to automatically learn and improve from experience without being explicitly programmed.
                                Machine learning focuses on the development of computer programs that can access data
                                and use it learn for themselves.</p>
                            <p><b class="theory_sub">Gender Identity</b> It is defined as a personal conception of
                                oneself as male or female (or rarely others).
                                This concept is intimately related to the concept of gender role, which is defined as
                                the outward manifestations
                                of personality that reflect the gender identity. Gender identity, in nearly all
                                instances, is self-identified,
                                as a result of a combination of inherent and extrinsic or environmental factors.</p>
                            <p><b class="theory_sub">Audio Features</b> An abstract representation of pieces of digital
                                music. Audio features are computed from the raw audio signal.
                                Simple features are the number of zero crossings of the audio signal or its centroid.
                                More sophisticated approaches,
                                such as MP3-based features, rhythm Patterns, Rhythm Histograms, or statistical Spectrum
                                Descriptors take into account,
                                for instance, findings from psycho-acoustics.</p>
                        </div>
                    </div>
                </div>
                <div class="row pt-3">
                    <div class="col-lg-12">
                        <h5>Models</h5>
                        <div class="content">
                            <p><b class="theory_sub">K-Nearest Neighbor Classifier (KNN)</b> It is an approach to data
                                classification that estimates how likely a data point is to be
                                a member of one group or the other depending on what group the data points nearest to it
                                are in.</p>
                            <p><b class="theory_sub">Random Forest or Random Decision Forest</b> These are an ensemble
                                learning method for classification, regression and other tasks
                                that operates by constructing a multitude of decision.</p>
                            <p><b class="theory_sub">Support Vector Machine (SVM)</b> It is a machine learning algorithm
                                that analyzes data for classification and regression analysis.
                                SVM is a supervised learning method that looks at data and sorts it into one of two
                                categories. An SVM outputs a map of the sorted
                                data with the margins between the two as far apart as possible.</p>
                            <p><b class="theory_sub">Naive Bayes Classfier</b> These are a family of simple
                                probabilistic classifiers based on applying Bayes' theorem with strong (naïve)
                                independence assumptions between the features. They are among the simplest Bayesian
                                network models.</p>
                        </div>
                    </div>
                </div>
                <div class="row pt-3">
                    <div class="col-lg-12">
                        <h5>Mission</h5>
                        <div class="content">
                            <p>Identifying the gender of a speaker from voice using various machine learning algorithms
                                and overcome the gender bias in case of voice
                                sample containing sounds like crying or yelling which is the drawback of the existing
                                system.</p>
                            <p><b class="theory_sub">Description</b> The system uses a set of Neural Networks with
                                Acoustic and Pitch related features. The pitch feature provides a good
                                discriminator between males’ and females’ voices. Speech classification and processing
                                and gender based recognition and classification
                                have been used for long period of time. We used some concepts developed over time to
                                implement gender recognition. Recent studies based
                                on gender detection shows that voice is converted first into different parameters based
                                on different parameters.<br>Main parameters
                                include pitch and frequency. Classification is done to differentiate male, female and
                                children. For this system is first trained with
                                the training data and test data are introduced and evaluated for the performance of the
                                system for these data. The results obtained
                                are different for different algorithms and seems to produce different results at
                                different times.</p>
                            <p style="text-indent: 50px;">Gender identification by voice is useful in speech-based
                                recognition systems which employ gender-dependent models.
                                Gender differentiation help to improve automatic emotion recognition from speech.
                                Classifying speaker’s gender is an important task in the
                                context of multimedia indexing. Gender identification can improve the prediction of
                                other speaker traits such as age and emotion, either
                                by jointly modelling gender with age (or emotion) or in a pipelined manner. Automatic
                                gender detection also useful in some cases of a
                                mobile healthcare system i.e., there are some pathologies, such as vocal fold cyst. For
                                detecting feeling like male sad, female anger, etc.
                                Differentiating audios and videos using tags. Spontaneous salutations. Helping personal
                                assistants to answer questions with gender-specific
                                results etc.</p>
                        </div>
                    </div>
                </div>
                <div class="row pt-3" id="references">
                    <div class="col-lg-12">
                        <h5>References</h5>
                        <div class="content">
                            <ol>
                                <li>Hadi Harb, Liming Chen, “Voice-Based Gender Identification in Multimedia
                                    Applications” J. Intell. Inf. Syst.. 24. 179-198. 10.1007/s10844-005-0322-8 (2005).
                                </li>
                                <li>Kunyu Chen, “Gender Identification by Voice”, Stanford University, (2014).</li>
                                <li>Sarah Ita Levitan, Taniya Mishra & Srinivas Bangalore, “Automatic identification of
                                    gender from speech”, 84-88. 10.21437/SpeechProsody.2016-18 (2016).</li>
                                <li>T. Jayasankar, K. Vinothkumar and Arputha Vijayaselvi, “Automatic Gender
                                    Identification in Speech Recognition by Genetic Algorithm”, Applied Mathematics &
                                    Information Sciences 11, No. 3, 907-913 (2017).</li>
                                <li>Remna R. Nair, Bhagya Vijayan, “Voice based Gender Recognition”, International
                                    Research Journal of Engineering and Technology (IRJET), Vol. 6, No. 5, May (2019).
                                </li>
                                <li>A Raahul, R Sapthagiri, K Pankaj and V Vijayarajan, “Voice based gender
                                    classification using machine learning”, IOP Conf. Series: Materials Science and
                                    Engineering 263 (2017).</li>
                            </ol>
                        </div>
                    </div>
                </div>
            </div>
            <div class="container-fluid" id="application_part">
                <h2>Our Model</h2>
                <div class="container">
                    <div class="row">
                        <div class="col-lg-12">
                            <h5>Requirements</h5>
                            <div class="content p-3">
                                <h6 class="sub_heading">Python Application</h6>
                                <ul class="list">
                                    <span class="list_sub">Packages: </span>
                                    <li>flask</li>
                                    <li>matplotlib</li>
                                    <li>mysql-connector</li>
                                    <li>numpy</li>
                                    <li>pandas</li>
                                    <li>sklearn</li>
                                    <li>pygal</li>
                                    <li>pydub</li>
                                </ul>
                                <h6 class="sub_heading">R Software</h6>
                                <ul class="list">
                                    <span class="list_sub">Libraries: </span>
                                    <li>tuneR</li>
                                    <li>warbleR</li>
                                    <li>seewave</li>
                                </ul>
                                <h6 class="sub_heading">Mysql Server.</h6>
                                <h6 class="sub_heading">Text Editor.</h6>
                                <h6 class="sub_heading">FFmpeg library</h6>
                            </div>
                        </div>
                    </div>
                    <div class="row" id="instruction_part">
                        <div class="col-lg-12">
                            <h5>Installation</h5>
                            <div class="content p-3">
                                <li>Download Python latest version</li>
                                <li>While installing Select Custom Installation and Choose ADD_PATH.</li>
                                <li>Install above Python packages. Command to install packages: </li>
                                <pre>pip install (package_name) </pre>
                                <p>Ex:
                                <p>
                                <p class="d-inline">If <b>python</b> is installed for ALL USERS (root directory):
                                <pre class="d-inline pl-0">pip install pandas</pre>
                                </p>
                                <p class="d-inline">else (AppData directory):
                                <pre class="d-inline pl-0">python -m pip install pandas</pre>
                                </p>
                                <li>Download R latest version</li>
                                <li>Setup environment variables for R.exe and RScript.exe as R and RScript located in (R
                                    directory)/bin </li>
                                <li>Install above R libraries. Command to install libraries:</li>
                                <p>Open R Console and type the following cmd:</p>
                                <p>
                                <pre>install.packages("package_name")</pre>
                                </p>
                                <p class="d-inline">Ex:
                                <pre class="d-inline pl-0">install.packages("tuneR")</pre>
                                </p>
                                <p>Note: <b> Inverted commas</b> are compulsory.</p>
                                <li>Run Mysql server or Just run wamp server and No need create any database.It will
                                    create automatically.</li>
                                <li>Extract and Paste above FlaskProject folder in ROOT or Desktop folder.</li>
                                <li>Open cmd prompt and Navigate to FlaskProject folder and type: <b>python app.py</b>
                                </li>
                                <li>It will execute and it gives url: http://127.0.0.1:5000/ or http://localhost:5000/
                                </li>
                                <li>Paste above url in Browser and Enjoy!!!</li>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </main>
        <footer class="footer"
            style="text-align: center; font-size: small;padding-bottom: 5px;color:rgba(33, 86, 107, 0.95);background-color: rgba(11, 12, 16,1);">
            Copyright&copy; 2020. Designed by Sanjay, Shivam, Tarun and Yashwanth</footer>
        <script type="text/javascript" src="{{ url_for('static', filename='js/jquery-3.4.1.slim.min.js') }}"></script>
        <script type="text/javascript" src="{{ url_for('static', filename='js/popper.min.js') }}"></script>
        <script type="text/javascript" src="{{ url_for('static', filename='js/bootstrap.min.js') }}"></script>
    </body>

</html>
